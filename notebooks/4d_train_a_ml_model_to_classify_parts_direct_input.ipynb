{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2e156c5-f68d-4a91-821f-66cb021a0aa0",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; gap: 10px;\">\n",
    "  <img src=\"../images/HOOPS_AI.jpg\" style=\"width: 20%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e7bd79-b8fb-4488-a615-458805b5f39d",
   "metadata": {},
   "source": [
    "# HOOPS AI: EXPERIMENTAL - Flow Trainer\n",
    "\n",
    "in this notebook we introduce the possibility to just generated the dgl files fo training in the Flow pipeline.\n",
    "We advice the reader to see the notebook 'ETL_pipeline_suing_flow_fabwave' for a complete study.\n",
    "\n",
    "when your dataset is ready, and you do not longer need to inspect the files and you have the collection fo cad files that you indeed would liek to train,\n",
    "\n",
    "then, use this example to generated only the dgl files, and set the DatasetLoader properly.\n",
    "\n",
    "The Training is perform directly on the dgl files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4649585-17db-49d8-a281-15d177e19aba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOOPS AI version :  1.0.0-b2dev8 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import hoops_ai\n",
    "import os\n",
    "\n",
    "hoops_ai.set_license(os.getenv(\"HOOPS_AI_LICENSE\"), validate= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4378d20a-4930-42b1-9d09-5513b50e1f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "flows_outputdir = pathlib.Path.cwd().joinpath(\"out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b4302c-4cce-4149-acc7-b8bdecb36a8b",
   "metadata": {},
   "source": [
    "## Prepared the ml input files for ml training\n",
    "\n",
    "this will only create the graph files (.dgl) for training the GraphClassification model\n",
    "\n",
    "This is optimized for Trianing once you knw what data you need to extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ed7b67b-2881-4bd0-a534-9dc327784df8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 18:07:10 | INFO | numexpr.utils | NumExpr defaulting to 16 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOOPS AI version :  1.0.0-b2dev8 \n",
      "\n",
      "Flow name: ETL_Fabwave_training_b2\n"
     ]
    }
   ],
   "source": [
    "# Import task functions from external module for ProcessPoolExecutor compatibility\n",
    "from scripts.cad_tasks_fabwave import gather_fabwave_files, encode_data_for_ml_training, get_flow_name\n",
    "flow_name = get_flow_name()\n",
    "\n",
    "print(f\"Flow name: {flow_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21f6ac7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting flow execution with parallel processing...\n",
      "|INFO| FLOW | ######### Flow 'ETL_Fabwave_training_b2' start #######\n",
      "|INFO| FLOW | \n",
      "Flow Execution Summary\n",
      "|INFO| FLOW | ==================================================\n",
      "|INFO| FLOW | Task 1: gather fabwave files\n",
      "|INFO| FLOW |     Inputs : cad_datasources\n",
      "|INFO| FLOW |     Outputs: cad_dataset\n",
      "|INFO| FLOW | Task 2: Preparing data for Exploring and ML training\n",
      "|INFO| FLOW |     Inputs : cad_dataset\n",
      "|INFO| FLOW |     Outputs: cad_files_encoded\n",
      "|INFO| FLOW | \n",
      "Task Dependencies:\n",
      "|INFO| FLOW | gather fabwave files has no dependencies.\n",
      "|INFO| FLOW | gather fabwave files --> Preparing data for Exploring and ML training\n",
      "|INFO| FLOW | ==================================================\n",
      "\n",
      "|INFO| FLOW | Executing ParallelTask 'gather fabwave files' with 1 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LuisSalazar\\MAIN\\repos\\ML-Initiative\\src\\hoops_ai\\flowmanager\\flow_builder.py:377: UserWarning: auto_dataset_export automatically disabled for memory storage type. Memory storage cannot be merged into datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6eabb9e257740708ce5e14932c070c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DATA INGESTION:   0%|                                                                            | 0/1 [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|INFO| FLOW | Executing ParallelTask 'Preparing data for Exploring and ML training' with 4572 items.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c6178383854ec497fc930bd10b4ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DATA TRANSFORMATION:   0%|                                                                    | 0/4572 [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|INFO| FLOW | Time taken: 673.28 seconds\n",
      "|INFO| FLOW | ######### Flow 'ETL_Fabwave_training_b2' end ######\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Run the flow to process all files\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting flow execution with parallel processing...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m flow_output, output_dict, flow_file \u001b[38;5;241m=\u001b[39m \u001b[43mcad_flow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcad_datasources\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasources_dir\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_ouput_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\MAIN\\repos\\ML-Initiative\\src\\hoops_ai\\flowmanager\\flow.py:510\u001b[0m, in \u001b[0;36mFlow.process\u001b[1;34m(self, inputs, clean_ouput_dir)\u001b[0m\n\u001b[0;32m    507\u001b[0m         force_sequential \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    508\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m configured for sequential execution.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 510\u001b[0m task_instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutor\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m    511\u001b[0m     task_class\u001b[38;5;241m=\u001b[39mtask_class,\n\u001b[0;32m    512\u001b[0m     items\u001b[38;5;241m=\u001b[39mitems,\n\u001b[0;32m    513\u001b[0m     force_sequential\u001b[38;5;241m=\u001b[39mforce_sequential,\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtask_kwargs\n\u001b[0;32m    515\u001b[0m )\n\u001b[0;32m    516\u001b[0m task_instances\u001b[38;5;241m.\u001b[39mappend(task_instance)\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output_name \u001b[38;5;129;01min\u001b[39;00m task_instance\u001b[38;5;241m.\u001b[39mtask_outputs:\n",
      "File \u001b[1;32m~\\MAIN\\repos\\ML-Initiative\\src\\hoops_ai\\flowmanager\\tasks\\parallel_executor.py:793\u001b[0m, in \u001b[0;36mParallelExecutor.execute\u001b[1;34m(self, task_class, items, force_sequential, **task_kwargs)\u001b[0m\n\u001b[0;32m    791\u001b[0m all_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(items))\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(all_items), desc\u001b[38;5;241m=\u001b[39mdescription, dynamic_ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m--> 793\u001b[0m     res, errs, lgs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[43mrun_continuous_with_ram_guard\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_items_with_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlicense_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_license\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_available_gb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_available_gb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_available_percent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_available_percent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m        \u001b[49m\u001b[43mram_check_interval_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mram_check_interval_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_inflight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_workers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_limit_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexisting_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m        \u001b[49m\u001b[43minflight_occurrences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minflight_occurrences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoo_heavy_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoo_heavy_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    810\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    811\u001b[0m task_instance\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mextend(res)\n\u001b[0;32m    812\u001b[0m task_instance\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mextend(errs)\n",
      "File \u001b[1;32m~\\MAIN\\repos\\ML-Initiative\\src\\hoops_ai\\flowmanager\\tasks\\parallel_executor.py:396\u001b[0m, in \u001b[0;36mrun_continuous_with_ram_guard\u001b[1;34m(ctx, task_class, task_kwargs, all_items_with_idx, max_workers, license_key, min_available_gb, min_available_percent, ram_check_interval_s, max_inflight, time_limit_s, pbar, existing_pool, inflight_occurrences, too_heavy_files, log_dir, is_heavy_file_phase)\u001b[0m\n\u001b[0;32m    394\u001b[0m done_now \u001b[38;5;241m=\u001b[39m [ar \u001b[38;5;28;01mfor\u001b[39;00m ar \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(in_flight\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;28;01mif\u001b[39;00m ar\u001b[38;5;241m.\u001b[39mready()]\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done_now:\n\u001b[1;32m--> 396\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mram_check_interval_s\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ar \u001b[38;5;129;01min\u001b[39;00m done_now:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# data source\n",
    "datasources_dir = [str(pathlib.Path.cwd().parent.joinpath(\"packages\",\"cadfiles\",\"fabwave\"))]\n",
    "\n",
    "# Create and run the Data Flow\n",
    "cad_flow = hoops_ai.create_flow(\n",
    "    name=flow_name,\n",
    "    tasks=[gather_fabwave_files, encode_data_for_ml_training],\n",
    "    max_workers=4,\n",
    "    #debug=True,\n",
    "    flows_outputdir=str(flows_outputdir),\n",
    "    ml_task=\"Part Classification\",\n",
    "    storage_type = \"memory\",\n",
    "    #parallel_task_kwargs=parallel_task_kwargs,\n",
    "    export_visualization=False  # Disable visualization export\n",
    ")\n",
    "\n",
    "# Run the flow to process all files\n",
    "print(\"Starting flow execution with parallel processing...\")\n",
    "flow_output, output_dict, flow_file = cad_flow.process(inputs={'cad_datasources': datasources_dir}, clean_ouput_dir = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2372d2c8-73ab-4abe-b6a9-c0d9c65a86f0",
   "metadata": {},
   "source": [
    "## Define the data split and training conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52779c2d-1d00-418d-a5ef-036f6500603c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGL files directory: C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\notebooks\\out\\flows\\ETL_Fabwave_training_b2\\dgl\n",
      "Number of DGL files generated: 4546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3637, 455, 454)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hoops_ai.dataset import DatasetLoader \n",
    "# read the dgl files form the flow output and inject it to the dataset loader\n",
    "#dgl files\n",
    "dgl_dir = flows_outputdir.joinpath(\"flows\",flow_name, \"dgl\")\n",
    "print(f\"DGL files directory: {dgl_dir}\")\n",
    "# get all .ml file in that folder a list\n",
    "dgl_files = [str(f) for f in dgl_dir.glob(\"*.ml\")]\n",
    "print(f\"Number of DGL files generated: {len(dgl_files)}\")\n",
    "\n",
    "\n",
    "cadflowdataset = DatasetLoader(graph_files=dgl_files, file_code_start=1)\n",
    "\n",
    "cadflowdataset.split(key=\"random\", train=0.8, validation=0.1, test=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de175d",
   "metadata": {},
   "source": [
    "## Train GraphClassification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "582a38b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRAPH CLASSIFICATION - HOOPS GAT - MODEL\n"
     ]
    }
   ],
   "source": [
    "from hoops_ai.ml.EXPERIMENTAL import GraphClassification, FlowTrainer\n",
    "# Define the Graph Classification model\n",
    "\n",
    "PartClassification_HOOPS = GraphClassification(num_classes=45,\n",
    "                                               result_dir = flows_outputdir)\n",
    "\n",
    "flow_trainer_HOOPS = FlowTrainer(\n",
    "\n",
    "    flowmodel       = PartClassification_HOOPS,\n",
    "    datasetLoader   = cadflowdataset,\n",
    "    experiment_name = \"HOOPS_AI_train\",\n",
    "    result_dir      = flows_outputdir,\n",
    "    accelerator     = 'cpu',\n",
    "    devices         = 1, #[0]\n",
    "    max_epochs      = 1,\n",
    "    batch_size      = 32  # Use 32, 64 or 128 depending on your avaiable memory\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331a253d-d5c4-4bbc-9149-0317c73346ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#corrupted_items = flow_trainer_HOOPS.purify()\n",
    "#print(\"Removing corrupted items :\", len(corrupted_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "199814de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------\n",
      "GRAPH CLASSIFICATION - HOOPS GAT - MODEL - TRAINING STEP\n",
      "-----------------------------------------------------------------------------------\n",
      "Training batch size               : 32\n",
      "Adjusted learning rate (for batch): 0.002\n",
      "\n",
      "Train set contains                : 3637 samples (80.00%)\n",
      "Validation set contains           : 455 samples (10.01%)\n",
      "Test set contains                 : 454 samples (9.99%)\n",
      "Total samples                     : 4546\n",
      "Max Epoch                         : 1\n",
      "\n",
      "The trained model: C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\notebooks\\out\\ml_output\\HOOPS_AI_train\\0126\\181902\\best.ckpt\n",
      "\n",
      "To monitor the logs, run:\n",
      "tensorboard --logdir results/HOOPS_AI_train/0126/181902\n",
      "-----------------------------------------------------------------------------------\n",
      "        \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ab934960a940a28e4442e5d5c07912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LuisSalazar\\miniconda3\\envs\\hoops_ai_cpu_dev\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished. Model checkpoint saved in C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\notebooks\\out\\ml_output\\HOOPS_AI_train\\0126\\181902\\best.ckpt\n",
      "\n",
      "-----------------------------------------------------------------------------------\n",
      "GRAPH CLASSIFICATION - HOOPS GAT - MODEL - TESTING STEP\n",
      "-----------------------------------------------------------------------------------\n",
      "\n",
      "The trained model: C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\notebooks\\out\\ml_output\\HOOPS_AI_train\\0126\\181902\\best.ckpt\n",
      "\n",
      "Test set contains 454 training samples\n",
      "-----------------------------------------------------------------------------------\n",
      "        \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/LuisSalazar/MAIN/repos/HOOPS-AI-tutorials/notebooks/out/ml_output/HOOPS_AI_train/0126/181902/best.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m trained_HOOPS_model \u001b[38;5;241m=\u001b[39m flow_trainer_HOOPS\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining finished. Model checkpoint saved in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrained_HOOPS_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mflow_trainer_HOOPS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_HOOPS_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting finished\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\MAIN\\repos\\ML-Initiative\\src\\hoops_ai\\ml\\EXPERIMENTAL\\flow_trainer.py:380\u001b[0m, in \u001b[0;36mFlowTrainer.test\u001b[1;34m(self, trained_model_path)\u001b[0m\n\u001b[0;32m    372\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data\u001b[38;5;241m.\u001b[39mget_dataloader(\n\u001b[0;32m    373\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m    374\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    375\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers\n\u001b[0;32m    376\u001b[0m )\n\u001b[0;32m    378\u001b[0m \u001b[38;5;66;03m# Load model from checkpoint\u001b[39;00m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# Assuming that the checkpoint contains the same source model state_dict\u001b[39;00m\n\u001b[1;32m--> 380\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflowmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m#loaded_model = self.model.load_from_checkpoint(trained_model_path)\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# Start testing\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m#self.trainer.test(loaded_model, dataloaders=test_loader, ckpt_path=trained_model_path)\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtest(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, dataloaders\u001b[38;5;241m=\u001b[39mtest_loader, ckpt_path\u001b[38;5;241m=\u001b[39mtrained_model_path)\n",
      "File \u001b[1;32m~\\MAIN\\repos\\ML-Initiative\\src\\hoops_ai\\ml\\EXPERIMENTAL\\flow_model_graph_classification.py:111\u001b[0m, in \u001b[0;36mGraphClassification.retrieve_model\u001b[1;34m(self, check_point)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the PyTorch Lightning model used in this flow.\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_point \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# Pass all required parameters when loading from checkpoint\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_point\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_gnn_surface_encoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_gnn_surface_encoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph_emb_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_emb_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;66;03m# Ensure metric_storage is set for a newly created model\u001b[39;00m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmetric_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_storage\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\hoops_ai_cpu_dev\\lib\\site-packages\\pytorch_lightning\\core\\saving.py:137\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     65\u001b[0m ):\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_from_checkpoint(\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m    139\u001b[0m         checkpoint_path,\n\u001b[0;32m    140\u001b[0m         map_location,\n\u001b[0;32m    141\u001b[0m         hparams_file,\n\u001b[0;32m    142\u001b[0m         strict,\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    144\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\hoops_ai_cpu_dev\\lib\\site-packages\\pytorch_lightning\\core\\saving.py:184\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m     map_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m storage, loc: storage\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[1;32m--> 184\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hparams_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     extension \u001b[38;5;241m=\u001b[39m hparams_file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\hoops_ai_cpu_dev\\lib\\site-packages\\pytorch_lightning\\utilities\\cloud_io.py:46\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path_or_url, map_location)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload_state_dict_from_url(\u001b[38;5;28mstr\u001b[39m(path_or_url), map_location\u001b[38;5;241m=\u001b[39mmap_location)\n\u001b[0;32m     45\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path_or_url)\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(f, map_location\u001b[38;5;241m=\u001b[39mmap_location)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\hoops_ai_cpu_dev\\lib\\site-packages\\fsspec\\spec.py:1349\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[1;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1348\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[1;32m-> 1349\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(\n\u001b[0;32m   1350\u001b[0m         path,\n\u001b[0;32m   1351\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   1352\u001b[0m         block_size\u001b[38;5;241m=\u001b[39mblock_size,\n\u001b[0;32m   1353\u001b[0m         autocommit\u001b[38;5;241m=\u001b[39mac,\n\u001b[0;32m   1354\u001b[0m         cache_options\u001b[38;5;241m=\u001b[39mcache_options,\n\u001b[0;32m   1355\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1356\u001b[0m     )\n\u001b[0;32m   1357\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1358\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\hoops_ai_cpu_dev\\lib\\site-packages\\fsspec\\implementations\\local.py:210\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[1;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LocalFileOpener(path, mode, fs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\hoops_ai_cpu_dev\\lib\\site-packages\\fsspec\\implementations\\local.py:387\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[1;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;241m=\u001b[39m get_compression(path, compression)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[1;32m--> 387\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\hoops_ai_cpu_dev\\lib\\site-packages\\fsspec\\implementations\\local.py:392\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m--> 392\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression:\n\u001b[0;32m    394\u001b[0m             compress \u001b[38;5;241m=\u001b[39m compr[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/LuisSalazar/MAIN/repos/HOOPS-AI-tutorials/notebooks/out/ml_output/HOOPS_AI_train/0126/181902/best.ckpt'"
     ]
    }
   ],
   "source": [
    "trained_HOOPS_model = flow_trainer_HOOPS.train()\n",
    "print(f\"Training finished. Model checkpoint saved in {trained_HOOPS_model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be885210-ad9d-4cee-99ea-f37d5d5dba70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------\n",
      "GRAPH CLASSIFICATION - HOOPS GAT - MODEL - TESTING STEP\n",
      "-----------------------------------------------------------------------------------\n",
      "\n",
      "The trained model: C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\notebooks\\out\\ml_output\\HOOPS_AI_train\\0126\\181902\\best.ckpt\n",
      "\n",
      "Test set contains 454 training samples\n",
      "-----------------------------------------------------------------------------------\n",
      "        \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/LuisSalazar/MAIN/repos/HOOPS-AI-tutorials/notebooks/out/ml_output/HOOPS_AI_train/0126/181902/best.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mflow_trainer_HOOPS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_HOOPS_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting finished\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\MAIN\\repos\\ML-Initiative\\src\\hoops_ai\\ml\\EXPERIMENTAL\\flow_trainer.py:380\u001b[0m, in \u001b[0;36mFlowTrainer.test\u001b[1;34m(self, trained_model_path)\u001b[0m\n\u001b[0;32m    372\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data\u001b[38;5;241m.\u001b[39mget_dataloader(\n\u001b[0;32m    373\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m    374\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    375\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers\n\u001b[0;32m    376\u001b[0m )\n\u001b[0;32m    378\u001b[0m \u001b[38;5;66;03m# Load model from checkpoint\u001b[39;00m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# Assuming that the checkpoint contains the same source model state_dict\u001b[39;00m\n\u001b[1;32m--> 380\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflowmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m#loaded_model = self.model.load_from_checkpoint(trained_model_path)\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# Start testing\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m#self.trainer.test(loaded_model, dataloaders=test_loader, ckpt_path=trained_model_path)\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtest(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, dataloaders\u001b[38;5;241m=\u001b[39mtest_loader, ckpt_path\u001b[38;5;241m=\u001b[39mtrained_model_path)\n",
      "File \u001b[1;32m~\\MAIN\\repos\\ML-Initiative\\src\\hoops_ai\\ml\\EXPERIMENTAL\\flow_model_graph_classification.py:111\u001b[0m, in \u001b[0;36mGraphClassification.retrieve_model\u001b[1;34m(self, check_point)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the PyTorch Lightning model used in this flow.\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_point \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# Pass all required parameters when loading from checkpoint\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_point\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_gnn_surface_encoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_gnn_surface_encoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph_emb_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_emb_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;66;03m# Ensure metric_storage is set for a newly created model\u001b[39;00m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmetric_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_storage\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\hoops_ai_cpu_dev\\lib\\site-packages\\pytorch_lightning\\core\\saving.py:137\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     65\u001b[0m ):\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_from_checkpoint(\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m    139\u001b[0m         checkpoint_path,\n\u001b[0;32m    140\u001b[0m         map_location,\n\u001b[0;32m    141\u001b[0m         hparams_file,\n\u001b[0;32m    142\u001b[0m         strict,\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    144\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\hoops_ai_cpu_dev\\lib\\site-packages\\pytorch_lightning\\core\\saving.py:184\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m     map_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m storage, loc: storage\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[1;32m--> 184\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hparams_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     extension \u001b[38;5;241m=\u001b[39m hparams_file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\hoops_ai_cpu_dev\\lib\\site-packages\\pytorch_lightning\\utilities\\cloud_io.py:46\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path_or_url, map_location)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload_state_dict_from_url(\u001b[38;5;28mstr\u001b[39m(path_or_url), map_location\u001b[38;5;241m=\u001b[39mmap_location)\n\u001b[0;32m     45\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path_or_url)\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(f, map_location\u001b[38;5;241m=\u001b[39mmap_location)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\hoops_ai_cpu_dev\\lib\\site-packages\\fsspec\\spec.py:1349\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[1;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1348\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[1;32m-> 1349\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(\n\u001b[0;32m   1350\u001b[0m         path,\n\u001b[0;32m   1351\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   1352\u001b[0m         block_size\u001b[38;5;241m=\u001b[39mblock_size,\n\u001b[0;32m   1353\u001b[0m         autocommit\u001b[38;5;241m=\u001b[39mac,\n\u001b[0;32m   1354\u001b[0m         cache_options\u001b[38;5;241m=\u001b[39mcache_options,\n\u001b[0;32m   1355\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1356\u001b[0m     )\n\u001b[0;32m   1357\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1358\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\hoops_ai_cpu_dev\\lib\\site-packages\\fsspec\\implementations\\local.py:210\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[1;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LocalFileOpener(path, mode, fs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\hoops_ai_cpu_dev\\lib\\site-packages\\fsspec\\implementations\\local.py:387\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[1;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;241m=\u001b[39m get_compression(path, compression)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[1;32m--> 387\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\hoops_ai_cpu_dev\\lib\\site-packages\\fsspec\\implementations\\local.py:392\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m--> 392\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression:\n\u001b[0;32m    394\u001b[0m             compress \u001b[38;5;241m=\u001b[39m compr[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/LuisSalazar/MAIN/repos/HOOPS-AI-tutorials/notebooks/out/ml_output/HOOPS_AI_train/0126/181902/best.ckpt'"
     ]
    }
   ],
   "source": [
    "flow_trainer_HOOPS.test(trained_HOOPS_model)\n",
    "print(f\"Testing finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bc5a13-a4ed-433d-bb69-892fd4848385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HOOPS AI (GPU)",
   "language": "python",
   "name": "hoops_ai_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
