{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2e156c5-f68d-4a91-821f-66cb021a0aa0",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; gap: 10px;\">\n",
    "  <img src=\"../images/HOOPS_AI.jpg\" style=\"width: 20%;\">\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e7bd79-b8fb-4488-a615-458805b5f39d",
   "metadata": {},
   "source": [
    "# HOOPS AI: EXPERIMENTAL - Flow Trainer\n",
    "\n",
    "## Purpose\n",
    "`FlowTrainer` orchestrates the complete training workflow for Flow Models, handling:\n",
    "\n",
    "- Dataset loading and splitting (train/validation/test)\n",
    "- Model initialization and checkpointing\n",
    "- Training loop with PyTorch Lightning\n",
    "- Metric logging and visualization\n",
    "- Data quality validation (purify method)\n",
    "\n",
    "## Core Components:\n",
    "\n",
    "* flowmodel (FlowModel): Initialized FlowModel implementation\n",
    "* datasetLoader (DatasetLoader): Dataset with train/val/test splits\n",
    "\n",
    "## Training Configuration:\n",
    "\n",
    "* batch_size (int): Samples per training batch (default: 64)\n",
    "* num_workers (int): DataLoader worker processes (default: 0)\n",
    "* experiment_name (str): Name for logging and checkpoints\n",
    "* accelerator (str): 'cpu', 'gpu', or 'tpu' (default: 'cpu')\n",
    "* devices (int or 'auto'): Number of devices to use (default: 'auto')\n",
    "* gradient_clip_val (float): Gradient clipping threshold (default: 1.0)\n",
    "* max_epochs (int): Maximum training epochs (default: 100)\n",
    "* learning_rate (float): Initial learning rate (default: 0.002)\n",
    "* result_dir (str): Output directory for results\n",
    "\n",
    "```python\n",
    "\n",
    "class FlowTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        flowmodel: FlowModel = None,        \n",
    "        datasetLoader: DatasetLoader = None,\n",
    "        ...\n",
    "    ):\n",
    "        \n",
    "    def train(self) -> str\n",
    "    def test(self, checkpoint_path: str = None) -> Dict[str, float]:\n",
    "    def purify(self) -> List[int]:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4649585-17db-49d8-a281-15d177e19aba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ Using TEST LICENSE (expires February 8th, 2026 - 12 days remaining)\n",
      "   For production use, obtain your own license from Tech Soft 3D\n",
      "HOOPS AI version :  1.0.0-b2dev7 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import hoops_ai\n",
    "import os\n",
    "\n",
    "hoops_ai.set_license(hoops_ai.use_test_license(), validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4378d20a-4930-42b1-9d09-5513b50e1f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "from hoops_ai.dataset import DatasetLoader \n",
    "from hoops_ai.ml.EXPERIMENTAL import GraphClassification\n",
    "from hoops_ai.ml.EXPERIMENTAL import FlowTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b4302c-4cce-4149-acc7-b8bdecb36a8b",
   "metadata": {},
   "source": [
    "## Define the dataset already prepared for ml training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ed7b67b-2881-4bd0-a534-9dc327784df8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\packages\\flows\\ETL_Fabwave_training_b2\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "flow_name = \"ETL_Fabwave_training_b2\" \n",
    "\n",
    "flow_root_dir = pathlib.Path.cwd().parent.joinpath(\"packages\", \"flows\", flow_name)\n",
    "print(flow_root_dir)\n",
    "\n",
    "myFlow_info        = str(flow_root_dir.joinpath(f\"{flow_name}.infoset\"))\n",
    "myFlow_dataset     = str(flow_root_dir.joinpath(f\"{flow_name}.dataset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2372d2c8-73ab-4abe-b6a9-c0d9c65a86f0",
   "metadata": {},
   "source": [
    "## Define the data split and training conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52779c2d-1d00-418d-a5ef-036f6500603c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DatasetExplorer] Default local cluster started: <Client: 'tcp://127.0.0.1:61979' processes=1 threads=16, memory=7.45 GiB>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb02bf6221384420906c803e062ea10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing file info:   0%|          | 0/4528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Found 8 files with invalid IDs (negative or non-numeric). Filtering them out.\n",
      "Warning: 1 file codes are missing from file_info\n",
      "DEBUG: Successfully built file lists with 4520 files out of 4528 original file codes\n",
      "\n",
      "============================================================\n",
      "DATASET STRUCTURE OVERVIEW\n",
      "============================================================\n",
      "\n",
      "Group: Labels\n",
      "------------------------------\n",
      "  file_id_code_Labels: (4533,) (int64)\n",
      "  part_label: (4533,) (float64)\n",
      "\n",
      "Group: edges\n",
      "------------------------------\n",
      "  edge_convexities: (314766,) (int32)\n",
      "  edge_dihedral_angles: (314766,) (float32)\n",
      "  edge_indices: (314766,) (int32)\n",
      "  edge_lengths: (314766,) (float32)\n",
      "  edge_types: (314766,) (int32)\n",
      "  edge_u_grids: (314766, 10, 6) (float32)\n",
      "  file_id_code_edges: (314766,) (int64)\n",
      "\n",
      "Group: face_mesh\n",
      "------------------------------\n",
      "  face_mesh_adj: (122099, 10000) (float32)\n",
      "  file_id_code_face_mesh: (122099,) (int64)\n",
      "\n",
      "Group: faces\n",
      "------------------------------\n",
      "  face_areas: (122099,) (float32)\n",
      "  face_discretization: (122099, 100, 7) (float32)\n",
      "  face_indices: (122099,) (int32)\n",
      "  face_loops: (122099,) (int32)\n",
      "  face_types: (122099,) (int32)\n",
      "  file_id_code_faces: (122099,) (int64)\n",
      "\n",
      "Group: graph\n",
      "------------------------------\n",
      "  edges_destination: (314766,) (int32)\n",
      "  edges_source: (314766,) (int32)\n",
      "  file_id_code_graph: (314766,) (int64)\n",
      "  num_nodes: (314766,) (int64)\n",
      "\n",
      "============================================================\n",
      "Dataset split by part_label: Train=3616, Validation=452, Test=452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3616, 452, 452)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solid_classification = GraphClassification(num_classes=45,use_gnn_surface_encoder=False, result_dir = flow_root_dir)\n",
    "\n",
    "cadflowdataset = DatasetLoader(merged_store_path = myFlow_dataset, parquet_file_path=myFlow_info)\n",
    "\n",
    "cadflowdataset.split(key=\"part_label\", group=\"Labels\", train=0.8, validation=0.1, test=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2a21b9-38f4-46dc-b187-4aab095c1fb4",
   "metadata": {},
   "source": [
    "## Define the Flow Trainer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275bce21-6538-48f9-84e7-712e999757ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRAPH CLASSIFICATION - UVNET - MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "flow_trainer = FlowTrainer(\n",
    "\n",
    "    flowmodel       = solid_classification,\n",
    "    datasetLoader   = cadflowdataset,\n",
    "    experiment_name = \"HOOPS_AI_train\",\n",
    "    result_dir      = flow_root_dir,\n",
    "    accelerator     = 'cpu',\n",
    "    devices         = 1, #[0]\n",
    "    max_epochs      = 3,\n",
    "    batch_size      = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75cf579-5365-4e97-b1b9-ad2827051ea5",
   "metadata": {},
   "source": [
    "### Train and store ml model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6452c345-748e-47f7-b440-2b187e073abd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------\n",
      "GRAPH CLASSIFICATION - UVNET - MODEL - TRAINING STEP\n",
      "-----------------------------------------------------------------------------------\n",
      "Training batch size               : 32\n",
      "Adjusted learning rate (for batch): 0.002\n",
      "\n",
      "Train set contains                : 3616 samples (80.00%)\n",
      "Validation set contains           : 452 samples (10.00%)\n",
      "Test set contains                 : 452 samples (10.00%)\n",
      "Total samples                     : 4520\n",
      "Max Epoch                         : 3\n",
      "\n",
      "The trained model: C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\packages\\flows\\ETL_Fabwave_training_b2\\ml_output\\HOOPS_AI_train\\0126\\151710\\best.ckpt\n",
      "\n",
      "To monitor the logs, run:\n",
      "tensorboard --logdir results/HOOPS_AI_train/0126/151710\n",
      "-----------------------------------------------------------------------------------\n",
      "        \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e8760a365c405da945702a2f85dac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LuisSalazar\\miniconda3\\envs\\hoops_ai_cpu_dev\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished. Model checkpoint saved in C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\packages\\flows\\ETL_Fabwave_training_b2\\ml_output\\HOOPS_AI_train\\0126\\151710\\best.ckpt\n"
     ]
    }
   ],
   "source": [
    "#corrupted_files = flow_trainer.purify()\n",
    "#print(corrupted_files)\n",
    "\n",
    "trained_model_path = flow_trainer.train()\n",
    "print(f\"Training finished. Model checkpoint saved in {trained_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6eb91a-c64d-4b9d-bcdd-6f962289fd12",
   "metadata": {},
   "source": [
    "### Test output ml model using test subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5bde0a9-1be6-407c-a4a1-182d37345f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hoops_ai.ml.EXPERIMENTAL.flow_trainer.FlowTrainer object at 0x000001DCB07055B0>\n"
     ]
    }
   ],
   "source": [
    "print(flow_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69abd764-a9eb-435b-925d-d2eb66c2295a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------\n",
      "GRAPH CLASSIFICATION - UVNET - MODEL - TESTING STEP\n",
      "-----------------------------------------------------------------------------------\n",
      "\n",
      "The trained model: C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\packages\\flows\\ETL_Fabwave_training_b2\\ml_output\\HOOPS_AI_train\\0126\\151710\\best.ckpt\n",
      "\n",
      "Test set contains 452 training samples\n",
      "-----------------------------------------------------------------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flow_trainer.test(trained_model_path)\n",
    "print(f\"Testing finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff91ed-1287-4052-8650-cd0ab9ec1092",
   "metadata": {},
   "source": [
    "# Make inference, test your current trained model\n",
    "\n",
    "The `FlowInference` class handles inference with trained models. It provides methods for preprocessing CAD data, making predictions, and post-processing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c88276-ed9e-4b27-8c1c-436b8e408c5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from hoops_ai.ml.EXPERIMENTAL import FlowInference\n",
    "from hoops_ai.cadaccess import HOOPSLoader, HOOPSModel, HOOPSTools\n",
    "result_dir=pathlib.Path.cwd().joinpath(\"out\",\"fabwave\")\n",
    "\n",
    "#inference_model = FlowInference(cad_loader = HOOPSLoader(), flowmodel = GraphClassification(num_classes=45, use_gnn_surface_encoder=False, result_dir=result_dir))\n",
    "inference_model = FlowInference(cad_loader = HOOPSLoader(), flowmodel = solid_classification)\n",
    "inference_model.load_from_checkpoint(trained_model_path)\n",
    "\n",
    "labels_description = {\n",
    "    0: \"Bearings\", 1: \"Bolts\", 2: \"Brackets\", 3: \"Bushing\", 4: \"Bushing_Damping_Liners\",\n",
    "    5: \"Collets\", 6: \"Gasket\", 7: \"Grommets\", 8: \"HeadlessScrews\", 9: \"Hex_Head_Screws\",\n",
    "    10: \"Keyway_Shaft\", 11: \"Machine_Key\", 12: \"Nuts\", 13: \"O_Rings\", 14: \"Thumb_Screws\",\n",
    "    15: \"Pipe_Fittings\", 16: \"Pipe_Joints\", 17: \"Pipes\", 18: \"Rollers\", 19: \"Rotary_Shaft\",\n",
    "    20: \"Shaft_Collar\", 21: \"Slotted_Flat_Head_Screws\", 22: \"Socket_Head_Screws\", 23: \"Washers\",\n",
    "    24: \"Boxes\", 25: \"Cotter_Pin\", 26: \"External Retaining Rings\", 27: \"Eyesbolts With Shoulders\",\n",
    "    28: \"Fixed Cap Flange\", 29: \"Gear Rod Stock\", 30: \"Gears\", 31: \"Holebolts With Shoulders\",\n",
    "    32: \"Idler Sprocket\", 33: \"Miter Gear Set Screw\", 34: \"Miter Gears\", 35: \"Rectangular Gear Rack\",\n",
    "    36: \"Routing EyeBolts Bent Closed Eye\", 37: \"Sleeve Washers\", 38: \"Socket-Connect Flanges\",\n",
    "    39: \"Sprocket Taper-Lock Bushing\", 40: \"Strut Channel Floor Mount\", 41: \"Strut Channel Side-Side\",\n",
    "    42: \"Tag Holder\", 43: \"Webbing Guide\", 44: \"Wide Grip External Retaining Ring\"\n",
    "}\n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb2310-bdd0-435b-b742-05e92312cd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from pathlib import Path\n",
    "from IPython.display import Image, display, HTML\n",
    "\n",
    "def cad_detect(cadfile: str):\n",
    "    # Generate a unique name based on file content or path\n",
    "    cad_path = Path(cadfile)\n",
    "    name_hash = hashlib.md5(str(cad_path).encode()).hexdigest()[:8]\n",
    "    export_name = f\"{cad_path.stem}_{name_hash}\"\n",
    "\n",
    "    ml_input = inference_model.preprocess(str(cadfile))    \n",
    "    predictions = inference_model.predict_and_postprocess(ml_input)\n",
    "\n",
    "    # Format output as \"labels_description: probability %\"\n",
    "    result = []\n",
    "    topk = 1\n",
    "    for i in range(topk):  # Top n predictions\n",
    "        class_idx = predictions[0, 0, i]  # Class index for the first batch item\n",
    "        probability = predictions[0, 1, i]  # Probability for the first batch item\n",
    "        result.append(f\"{labels_description[class_idx]}: {probability}%\")\n",
    "\n",
    "    tools = HOOPSTools()\n",
    "    loader = HOOPSLoader()\n",
    "    model = loader.create_from_file(str(cadfile))\n",
    "    export_path = result_dir / f\"{export_name}\"\n",
    "    tools.exportStreamCache(model, str(export_path), is_white_background=True, overwrite=True)\n",
    "\n",
    "    image = Image(filename=f\"{export_path}_white.png\")\n",
    "\n",
    "    return \"\\n\".join(result), image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32db883a-3f70-4abf-ac1f-704887ed10c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0fceb5-7eea-44bc-a165-cafcd470932b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "demofile_dir  = pathlib.Path.cwd().parent.joinpath(\"packages\", \"cadfiles\")    \n",
    "\n",
    "cadfiles = [\n",
    "    \"nuts_fabwave.x_t\",\n",
    "    \"bearings_fabwave.step\",\n",
    "    \"gear_fabwave.iges\",\n",
    "    \"pn_verschr_r1.prt.1\",\n",
    "    \"collets_fabwave.sat\"\n",
    "]\n",
    "\n",
    "import base64\n",
    "\n",
    "cells = []\n",
    "for cadfile in cadfiles:\n",
    "    prediction, image = cad_detect(demofile_dir / cadfile)\n",
    "    img_path = Path(image.filename)\n",
    "\n",
    "    # Read and encode the image as base64\n",
    "    with open(img_path, \"rb\") as f:\n",
    "        encoded = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "        img_data = f\"data:image/png;base64,{encoded}\"\n",
    "\n",
    "    # HTML cell with embedded image and prediction\n",
    "    cell = f\"\"\"\n",
    "    <td style=\"text-align:center; padding:10px;\">\n",
    "        <img src=\"{img_data}\" width=\"200\"/><br/>\n",
    "        <pre style=\"font-size:12px;\">{prediction}</pre>\n",
    "    </td>\n",
    "    \"\"\"\n",
    "    cells.append(cell)\n",
    "\n",
    "# Wrap cells in a single table row\n",
    "html = f\"\"\"\n",
    "<table style=\"width:100%; table-layout:fixed;\">\n",
    "    <tr>\n",
    "        {''.join(cells)}\n",
    "    </tr>\n",
    "</table>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d6933-74c1-425a-b396-0dc026cc5c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15fca5b8-f405-403a-b0b4-ded71ced2d0d",
   "metadata": {},
   "source": [
    "## Metric Explorer. Review the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e427f98-96ec-4fba-8d59-ea304d3661e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from hoops_ai.ml import MetricExplorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd612e0-d8a2-42ce-b0d6-a63404c26d84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_explorer = MetricExplorer(metric_or_flow_file_path=str(flow_root_dir.joinpath(\"ml.metrics\")))\n",
    "metric_explorer.print_table_of_content()\n",
    "\n",
    "steps, values = metric_explorer.smooth_trend_metric(\"train_loss\",12)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(steps, values, label='Training Loss', color='blue')\n",
    "plt.xlabel('Training Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Trend')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b925acf6-6041-41ad-992d-6fc7b4962988",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_explorer.compute_confusion_matrix_stats('confusion_matrix', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58adb4cd-3ad5-4987-9a6f-9d26ae06eed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_explorer.best_worst_categories('class_accuracy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece6e37-7618-4f7c-add4-600076ab230f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bcbba7-dbab-45f6-b462-e1694e837c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HOOPS AI (CPU-DEV)",
   "language": "python",
   "name": "hoops_ai_cpu_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
