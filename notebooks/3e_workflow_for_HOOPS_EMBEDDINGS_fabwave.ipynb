{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"display: flex; gap: 10px;\">\n",
    "  <img src=\"../images/HOOPS_AI.jpg\" style=\"width: 20%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training your custom HOOPS Embeddings Model\n",
    "\n",
    "> **Purpose**: This document is for **Data Scientists** who want to **Train custom HOOPS Embedding models**. \n",
    "\n",
    "## Overview\n",
    "\n",
    "The `EmbeddingFlowModel` is a specialized FlowModel implementation designed for **training** shape embeddings model from CAD data using contrastive learning.\n",
    "\n",
    "Thus, enabling data scientists to train custom HOOPS Embedding models on their own CAD datasets.\n",
    "\n",
    "### Training → Production Workflow\n",
    "\n",
    "1. **Train** a custom HOOPS Embeddings using `EmbeddingFlowModel` + `FlowTrainer` (this document)\n",
    "2. **Register** the trained model with `HOOPSEmbeddings.register_model()` \n",
    "3. **Deploy** for production use via `HOOPSEmbeddings` API (see notebook HOOPS_embeddings_cad_search_fabwave for an example)\n",
    "\n",
    "### When to Train Custom Models\n",
    "\n",
    "- Your CAD parts have unique geometric characteristics not captured by pre-trained models\n",
    "- You need domain-specific embeddings (e.g., specific industry, manufacturing process)\n",
    "- You have a large proprietary dataset to learn from\n",
    "- You want to optimize embedding dimensions for your use case\n",
    "\n",
    "**Note**: HOOPS AI's provided a pre-trained model (e.g., `ts3d_1M_dual_v1`) that can be used directly. See the [production guide](../Embeddings%20&%20Similarity/embeddings_and_retrieval_guide.md) on how to use it directly. Trained on a large dataset with nearly 1M parts from **public datasets (ABC, fabwave, etc)**. \n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Contrastive Learning**: Learns shape representations by distinguishing between similar and dissimilar CAD geometries\n",
    "- **Flexible Architecture**: Configurable embedding dimensions, projection layers, and training parameters\n",
    "- **Unsupervised Training**: No labels required per CAD file - learns from geometric structure alone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOOPS AI version :  1.0.0-b2dev2 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LuisSalazar\\AppData\\Local\\Temp\\ipykernel_25316\\3362318196.py:4: UserWarning: ⚠️ TEST LICENSE expires in 6 days (January 31, 2026)!\n",
      "   Please obtain your own license from Tech Soft 3D.\n",
      "   Visit: https://www.techsoft3d.com/contact/\n",
      "  hoops_ai.set_license(hoops_ai.use_test_license(), validate=False)\n"
     ]
    }
   ],
   "source": [
    "import hoops_ai\n",
    "import os\n",
    "\n",
    "hoops_ai.set_license(hoops_ai.use_test_license(), validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import hoops_ai\n",
    "from hoops_ai.dataset import DatasetLoader\n",
    "from hoops_ai.ml.EXPERIMENTAL import FlowTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOOPS AI version :  1.0.0-b2dev2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we define our tasks in a separate file for multprocessing compatibility\n",
    "from scripts.cad_tasks_embeddings import EmbeddingModel, flows_outputdir, get_flow_name, gather_cad_files, encode_data_for_ml_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructor Parameters\n",
    "\n",
    "### Essential Training Parameters\n",
    "\n",
    "#### `emb_dim` (int, default: 1024)\n",
    "The dimensionality of the learned embeddings. This determines the size of the vector representation for each CAD shape.\n",
    "- Higher dimensions can capture more detailed features but increase computational cost\n",
    "- Typical values: 512, 1024, 2048\n",
    "\n",
    "#### `lr` (float, default: 3e-4)\n",
    "Learning rate for the optimizer during training.\n",
    "- Controls the step size for gradient descent updates\n",
    "- May need adjustment based on batch size and dataset characteristics\n",
    "\n",
    "### Temperature Parameters\n",
    "\n",
    "These parameters control the contrastive loss function's sensitivity to similarities:\n",
    "\n",
    "#### `temp_init` (float, default: 0.05)\n",
    "Initial temperature value for the contrastive loss.\n",
    "- Lower values make the model more discriminative\n",
    "- Higher values create softer similarities\n",
    "\n",
    "#### `temp_min` (float, default: 0.01)\n",
    "Minimum allowed temperature during training.\n",
    "\n",
    "#### `temp_max` (float, default: 0.20)\n",
    "Maximum allowed temperature during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Pipeline\n",
    "\n",
    "The `EmbeddingFlowModel` training requires a preprocessing pipeline that gathers CAD files and extract the cad data needed for the training. Here's a complete example using the FlowManager decorators:\n",
    "\n",
    "**Task 1 - Extract**: Uses `@flowtask.extract` to gather CAD files from local storage using `CADFileRetriever`. Supports multiple CAD formats and parallel processing.\n",
    "\n",
    "**Task 2 - Prepare data for Embeddings Training**: Uses `@flowtask.transform` decorator which automatically initializes and provide an optimized datastorage and a parallel handling of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\packages\\cadfiles\\fabwave\n"
     ]
    }
   ],
   "source": [
    "datasources_dir = pathlib.Path.cwd().parent.joinpath(\"packages\",\"cadfiles\",\"fabwave\")\n",
    "print(datasources_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETl pipeline preparation of the data to be used as ML-input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|INFO| FLOW | ######### Flow 'HOOPS Embedding Training' start #######\n",
      "|WARNING| FLOW | Cleaning up existing flow directory: C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\notebooks\\out\\flows\\HOOPS Embedding Training\n",
      "|WARNING| FLOW | Removing all previous outputs for flow 'HOOPS Embedding Training' to avoid build conflicts.\n",
      "|INFO| FLOW | Flow directory successfully cleaned and recreated: C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\notebooks\\out\\flows\\HOOPS Embedding Training\n",
      "|INFO| FLOW | \n",
      "Flow Execution Summary\n",
      "|INFO| FLOW | ==================================================\n",
      "|INFO| FLOW | Task 1: gather cad files\n",
      "|INFO| FLOW |     Inputs : cad_datasources\n",
      "|INFO| FLOW |     Outputs: cad_dataset\n",
      "|INFO| FLOW | Task 2: Extracting CAD ML-input for EmbeddingModel\n",
      "|INFO| FLOW |     Inputs : cad_dataset\n",
      "|INFO| FLOW |     Outputs: cad_files_encoded\n",
      "|INFO| FLOW | Task 3: AutoDatasetExportTask\n",
      "|INFO| FLOW |     Inputs : cad_files_encoded\n",
      "|INFO| FLOW |     Outputs: encoded_dataset, encoded_dataset_info, encoded_dataset_attribs\n",
      "|INFO| FLOW | \n",
      "Task Dependencies:\n",
      "|INFO| FLOW | gather cad files has no dependencies.\n",
      "|INFO| FLOW | gather cad files --> Extracting CAD ML-input for EmbeddingModel\n",
      "|INFO| FLOW | Extracting CAD ML-input for EmbeddingModel --> AutoDatasetExportTask\n",
      "|INFO| FLOW | ==================================================\n",
      "\n",
      "|INFO| FLOW | Executing ParallelTask 'gather cad files' with 1 items.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff6b633453945359d2505304d69066c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DATA INGESTION:   0%|                                                                            | 0/1 [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|INFO| FLOW | Executing ParallelTask 'Extracting CAD ML-input for EmbeddingModel' with 200 items.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b893b87477b4b389bc5ef1f1b3b9a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DATA TRANSFORMATION:   0%|                                                                     | 0/200 [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|INFO| FLOW | Executing SequentialTask 'AutoDatasetExportTask'.\n",
      "[DatasetMerger] Saved schema with 3 groups to metadata.json\n",
      "|INFO| FLOW | Auto dataset export completed in 15.26 seconds\n",
      "Sequential Task end=====================\n",
      "|INFO| FLOW | Time taken: 179.27 seconds\n",
      "|INFO| FLOW | ######### Flow 'HOOPS Embedding Training' end ######\n",
      "\n",
      "======================================================================\n",
      "FLOW EXECUTION COMPLETED SUCCESSFULLY\n",
      "======================================================================\n",
      "\n",
      "Dataset files created:\n",
      "  Main dataset: C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\notebooks\\out\\flows\\HOOPS Embedding Training\\HOOPS Embedding Training.dataset\n",
      "  Info dataset: C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\notebooks\\out\\flows\\HOOPS Embedding Training\\HOOPS Embedding Training.infoset\n",
      "  Attributes: C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\notebooks\\out\\flows\\HOOPS Embedding Training\\HOOPS Embedding Training.attribset\n",
      "  Flow file: C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\notebooks\\out/flows/HOOPS Embedding Training/HOOPS Embedding Training.flow\n",
      "\n",
      "Total processing time: 179.27 seconds\n",
      "Files processed: 200\n"
     ]
    }
   ],
   "source": [
    "# Create and run the Data Flow\n",
    "flow_name = get_flow_name() \n",
    "\n",
    "cad_flow = hoops_ai.create_flow(\n",
    "    name=flow_name,\n",
    "    tasks=[gather_cad_files, encode_data_for_ml_training],  # Imported from cad_tasks_embdedding.py\n",
    "    max_workers=6,  \n",
    "    flows_outputdir=str(flows_outputdir),\n",
    "    ml_task=\"custom HOOPS Embeddings model Demo\",\n",
    "    auto_dataset_export=True,  # Enable automatic dataset merging\n",
    "    #debug=True,  # Changed to True to enable debugging\n",
    "    export_visualization=False\n",
    ")\n",
    "\n",
    "# Run the flow to process all files\n",
    "flow_output, output_dict, flow_file = cad_flow.process(inputs={'cad_datasources': [str(datasources_dir)]}, clean_ouput_dir=True)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FLOW EXECUTION COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nDataset files created:\")\n",
    "print(f\"  Main dataset: {output_dict.get('flow_data', 'N/A')}\")\n",
    "print(f\"  Info dataset: {output_dict.get('flow_info', 'N/A')}\")\n",
    "print(f\"  Attributes: {output_dict.get('flow_attributes', 'N/A')}\")\n",
    "print(f\"  Flow file: {flow_file}\")\n",
    "print(f\"\\nTotal processing time: {output_dict.get('Duration [seconds]', {}).get('total', 0):.2f} seconds\")\n",
    "print(f\"Files processed: {output_dict.get('file_count', 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DatasetExplorer] Default local cluster started: <Client: 'tcp://127.0.0.1:53113' processes=1 threads=16, memory=7.45 GiB>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847c0ce8e78c4c7baddb350ea592e533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing file info:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dataset Table of Contents ---\n",
      "\n",
      "EDGES_GROUP:\n",
      "  EDGE_CONVEXITIES_DATA: Shape: (11406,), Dims: ('edge',), Size: 11406\n",
      "  EDGE_DIHEDRAL_ANGLES_DATA: Shape: (11406,), Dims: ('edge',), Size: 11406\n",
      "  EDGE_INDICES_DATA: Shape: (11406,), Dims: ('edge',), Size: 11406\n",
      "  EDGE_LENGTHS_DATA: Shape: (11406,), Dims: ('edge',), Size: 11406\n",
      "  EDGE_TYPES_DATA: Shape: (11406,), Dims: ('edge',), Size: 11406\n",
      "  EDGE_U_GRIDS_DATA: Shape: (11406, 10, 6), Dims: ('edge', 'dim_x', 'component'), Size: 684360\n",
      "  FILE_ID_CODE_EDGES_DATA: Shape: (11406,), Dims: ('edge',), Size: 11406\n",
      "\n",
      "FACES_GROUP:\n",
      "  FACE_AREAS_DATA: Shape: (4438,), Dims: ('face',), Size: 4438\n",
      "  FACE_DISCRETIZATION_DATA: Shape: (4438, 100, 7), Dims: ('face', 'sample', 'component'), Size: 3106600\n",
      "  FACE_INDICES_DATA: Shape: (4438,), Dims: ('face',), Size: 4438\n",
      "  FACE_LOOPS_DATA: Shape: (4438,), Dims: ('face',), Size: 4438\n",
      "  FACE_TYPES_DATA: Shape: (4438,), Dims: ('face',), Size: 4438\n",
      "  FILE_ID_CODE_FACES_DATA: Shape: (4438,), Dims: ('face',), Size: 4438\n",
      "\n",
      "GRAPH_GROUP:\n",
      "  EDGES_DESTINATION_DATA: Shape: (11406,), Dims: ('edge',), Size: 11406\n",
      "  EDGES_SOURCE_DATA: Shape: (11406,), Dims: ('edge',), Size: 11406\n",
      "  FILE_ID_CODE_GRAPH_DATA: Shape: (11406,), Dims: ('edge',), Size: 11406\n",
      "  NUM_NODES_DATA: Shape: (11406,), Dims: ('edge',), Size: 11406\n",
      "==================================\n",
      "Columns in file_info:\n",
      "                                 name   id                             description subset table_name\n",
      "0    02cf6b3631e3d6f2a245b1d933ed1e36    0  ...s\\STEP\\sshettigarsleevewasher20.stp    N/A  file_info\n",
      "1    033ebacd27b798bfb2e16b63faeee965    1  ...eeb-04c2-4489-bd5f-0f8e9606fe63.stp    N/A  file_info\n",
      "2    036507411e5d2a5405a7c520ddc5a7f4    2  ...792-5b5a-410e-a46b-883e0dd908c7.stp    N/A  file_info\n",
      "3    05ad127cbdb5469c73fb13c8b1c1f8a3    3  ...\\Hex_Head_Screws\\STEP\\stlfile84.stp    N/A  file_info\n",
      "4    06681e8bfc2f1d150f29c784e9653832    4  ...ba2-27a0-4915-a907-33dbab4222e8.stp    N/A  file_info\n",
      "5    075286bfe2eaed6421043e262186f551    5  ...f59-82c2-44d5-ac54-4e0f526e3967.stp    N/A  file_info\n",
      "6    0900037f4116d43a4479aefb37589e81    6  ...b05-ef9d-4ea6-b2a6-3e3fcb41c1fd.stp    N/A  file_info\n",
      "7    0ca2f2ea36cf0070250181d0260da746    7  ...745-97ac-438c-90fc-709db0ae92bf.stp    N/A  file_info\n",
      "8    0d6f64f25ca4a1860f9030d9cb5c0956    8  ...da8-9dea-4583-ac4f-3eb5a266486a.stp    N/A  file_info\n",
      "9    10b095458af4998bf2a2f7bcc9c2bdfe    9  ...ead_Screws\\STEP\\annatestscrew76.stp    N/A  file_info\n",
      "..                                ...  ...                                     ...    ...        ...\n",
      "190  f543e12c3388e470fad4da16b921c7a9  190  ...gs\\STEP\\exammodelsankuranubhav8.stp    N/A  file_info\n",
      "191  f586252790b8124a9213ce436116b04e  191  ...eef-2ea5-4b7a-ac43-29f2125e519f.stp    N/A  file_info\n",
      "192  fa04fdceb93e3db754bd032646a59dd9  192  ...103-4fe1-4499-8c63-26f646768822.stp    N/A  file_info\n",
      "193  fafc67b1738d4417b8b7a707e2210668  193  ...9bf-fe81-42fc-8dc5-2adafebeceee.stp    N/A  file_info\n",
      "194  fb5eb32ed1447985ea442a67898bf333  194  ...OTAL1000\\Gear Rod Stock\\STEP\\10.stp    N/A  file_info\n",
      "195  fc0cd609c2bdca7fbb39d574ea04d45d  195  ...180-75cb-42bd-8372-0b7b76f9148b.stp    N/A  file_info\n",
      "196  fc129a2cc3b9e56f348eef7ce8f6cda2  196  ...83d-b25d-4858-a47c-760aeac1adfb.stp    N/A  file_info\n",
      "197  fd1ec2a0caa2743cd97710f8fc71c9f7  197  ...c60-cb20-457b-a75f-02f7acebb9f3.stp    N/A  file_info\n",
      "198  fe3d02c9c2e0c2a4700eb58368efcc9c  198  ...30e-7b04-4430-9f8a-900cbb99f587.stp    N/A  file_info\n",
      "199  febade3a7566d6f7fdec0be465bdb60c  199  ...2c2-a443-442f-8b5f-27988a2d35a4.stp    N/A  file_info\n"
     ]
    }
   ],
   "source": [
    "from hoops_ai.dataset import DatasetExplorer\n",
    "\n",
    "explorer = DatasetExplorer(flow_output_file=str(flow_file))\n",
    "explorer.print_table_of_contents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we move towards running a training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\notebooks\\out\\flows\\HOOPS Embedding Training\n"
     ]
    }
   ],
   "source": [
    "flow_name = get_flow_name() \n",
    "flow_root_dir = flows_outputdir.joinpath(\"flows\", flow_name)\n",
    "print(flow_root_dir)\n",
    "\n",
    "myFlow_info        = str(flow_root_dir.joinpath(f\"{flow_name}.infoset\"))\n",
    "myFlow_dataset     = str(flow_root_dir.joinpath(f\"{flow_name}.dataset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DatasetExplorer] Default local cluster started: <Client: 'tcp://127.0.0.1:53256' processes=1 threads=16, memory=7.45 GiB>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cc7ebbe51543b882c35308754f4ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing file info:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET STRUCTURE OVERVIEW\n",
      "============================================================\n",
      "\n",
      "Group: edges\n",
      "------------------------------\n",
      "  edge_convexities: (11406,) (int32)\n",
      "  edge_dihedral_angles: (11406,) (float32)\n",
      "  edge_indices: (11406,) (int32)\n",
      "  edge_lengths: (11406,) (float32)\n",
      "  edge_types: (11406,) (int32)\n",
      "  edge_u_grids: (11406, 10, 6) (float32)\n",
      "  file_id_code_edges: (11406,) (int64)\n",
      "\n",
      "Group: faces\n",
      "------------------------------\n",
      "  face_areas: (4438,) (float32)\n",
      "  face_discretization: (4438, 100, 7) (float32)\n",
      "  face_indices: (4438,) (int32)\n",
      "  face_loops: (4438,) (int32)\n",
      "  face_types: (4438,) (int32)\n",
      "  file_id_code_faces: (4438,) (int64)\n",
      "\n",
      "Group: graph\n",
      "------------------------------\n",
      "  edges_destination: (11406,) (int32)\n",
      "  edges_source: (11406,) (int32)\n",
      "  file_id_code_graph: (11406,) (int64)\n",
      "  num_nodes: (11406,) (int64)\n",
      "\n",
      "============================================================\n",
      "DEBUG: file_codes type: <class 'numpy.ndarray'>, shape: (200,)\n",
      "DEBUG: file_codes range: 0 to 199\n",
      "DEBUG: first 10 file_codes: [0 1 2 3 4 5 6 7 8 9]\n",
      "DEBUG: df_info columns: ['name', 'id', 'description', 'subset', 'table_name']\n",
      "DEBUG: df_info shape: (200, 5)\n",
      "DEBUG: existing IDs type: <class 'str'>\n",
      "DEBUG: first 10 existing IDs: ['0' '1' '2' '3' '4' '5' '6' '7' '8' '9']\n",
      "DEBUG: existing IDs range: 0 to 99\n",
      "DEBUG: file_codes appear to be indices, mapping to actual IDs...\n",
      "DEBUG: Mapped 200 indices to 200 IDs\n",
      "DEBUG: First 10 mapped IDs: ['0' '1' '2' '3' '4' '5' '6' '7' '8' '9']\n",
      "DEBUG: Successfully built file lists with 200 files out of 200 original file codes\n",
      "Dataset split by face_types: Train=159, Validation=20, Test=21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(159, 20, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the already encoded dataset and perform the split\n",
    "cadflowdataset = DatasetLoader(merged_store_path = myFlow_dataset, parquet_file_path=myFlow_info)\n",
    "cadflowdataset.split(key='face_types', group=\"faces\",train=0.8, validation=0.1, test=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we define our trainer that will do the training job for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOOPS Embedding Model\n",
      "Batch size adjusted to 20 to train dataset size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "flow_trainer = FlowTrainer(\n",
    "\n",
    "    flowmodel       = EmbeddingModel, # imported from cad_tasks_embeddings.py\n",
    "    datasetLoader   = cadflowdataset,\n",
    "    experiment_name = \"HOOPS_AI_train\",\n",
    "    result_dir      = flow_root_dir,\n",
    "    accelerator     = 'cpu',\n",
    "    devices         = 1, #[0]\n",
    "    max_epochs      = 10,\n",
    "    batch_size      = 64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------\n",
      "HOOPS Embedding Model - TRAINING STEP\n",
      "-----------------------------------------------------------------------------------\n",
      "Training batch size               : 20\n",
      "Adjusted learning rate (for batch): 0.002\n",
      "\n",
      "Train set contains                : 159 samples (79.50%)\n",
      "Validation set contains           : 20 samples (10.00%)\n",
      "Test set contains                 : 21 samples (10.50%)\n",
      "Total samples                     : 200\n",
      "Max Epoch                         : 10\n",
      "\n",
      "The trained model: C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\notebooks\\out\\flows\\HOOPS Embedding Training\\ml_output\\HOOPS_AI_train\\0125\\004807\\best.ckpt\n",
      "\n",
      "To monitor the logs, run:\n",
      "tensorboard --logdir results/HOOPS_AI_train/0125/004807\n",
      "-----------------------------------------------------------------------------------\n",
      "        \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc4e4e7afb34384a390151ea91dbea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished. Model checkpoint saved in C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\notebooks\\out\\flows\\HOOPS Embedding Training\\ml_output\\HOOPS_AI_train\\0125\\004807\\best.ckpt\n"
     ]
    }
   ],
   "source": [
    "trained_model_path = flow_trainer.train()\n",
    "print(f\"Training finished. Model checkpoint saved in {trained_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\notebooks\\out\\flows\\HOOPS Embedding Training\\ml_output\\HOOPS_AI_train\\0125\\004807\\best.ckpt\n",
      "Loaded model weights from checkpoint at C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\notebooks\\out\\flows\\HOOPS Embedding Training\\ml_output\\HOOPS_AI_train\\0125\\004807\\best.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------\n",
      "HOOPS Embedding Model - TESTING STEP\n",
      "-----------------------------------------------------------------------------------\n",
      "\n",
      "The trained model: C:\\Users\\LuisSalazar\\MAIN\\repos\\HOOPS-AI-tutorials\\notebooks\\out\\flows\\HOOPS Embedding Training\\ml_output\\HOOPS_AI_train\\0125\\004807\\best.ckpt\n",
      "\n",
      "Test set contains 21 training samples\n",
      "-----------------------------------------------------------------------------------\n",
      "        \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef46a55e57cd46729e16eff61d2307a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/loss_curve      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     5.322879791259766     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/loss_surface     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    4.4033098220825195     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/loss_total      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     9.726189613342285     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/loss_curve     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5.322879791259766    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test/loss_surface    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   4.4033098220825195    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/loss_total     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    9.726189613342285    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing finished.\n"
     ]
    }
   ],
   "source": [
    "flow_trainer.test(trained_model_path)\n",
    "print(\"Testing finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "The output of a Flow EmbeddingsModel are the embeddings. This lsit of float values are difficult to understand and represents a learnable representation of your CAD file.\n",
    "\n",
    "Here, we are going to use the FLowInference to get the value for a new file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Initialize CAD loader (needed for ML inference later)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m loader \u001b[38;5;241m=\u001b[39m HOOPSLoader()\n\u001b[1;32m---> 10\u001b[0m inference_model \u001b[38;5;241m=\u001b[39m FlowInference(cad_loader \u001b[38;5;241m=\u001b[39m loader, flowmodel \u001b[38;5;241m=\u001b[39m EmbeddingFlowModel(result_dir\u001b[38;5;241m=\u001b[39m\u001b[43moutput_dir\u001b[49m))\n\u001b[0;32m     11\u001b[0m inference_model\u001b[38;5;241m.\u001b[39mload_from_checkpoint(trained_model_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_dir' is not defined"
     ]
    }
   ],
   "source": [
    "from hoops_ai.ml.EXPERIMENTAL import FlowInference\n",
    "from hoops_ai.ml.EXPERIMENTAL import EmbeddingFlowModel\n",
    "\n",
    "from hoops_ai.cadaccess import HOOPSLoader\n",
    "from hoops_ai.insights import CADViewer\n",
    "\n",
    "# Initialize CAD loader (needed for ML inference later)\n",
    "loader = HOOPSLoader()\n",
    "\n",
    "inference_model = FlowInference(cad_loader = loader, flowmodel = EmbeddingFlowModel(result_dir=flow_root_dir))\n",
    "inference_model.load_from_checkpoint(trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_input = inference_model.preprocess(cad_file_test)    \n",
    "predictions = inference_model.predict_and_postprocess(ml_input)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As opposite of the other two ml models of this library, the inference needs to be complemented with a vector store.\n",
    "\n",
    "This tutorial ends here, we invite the reader to check out the notebook HOOPS EMBEDDINGS for CAD SEARCH to further details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering Your Trained Model for Production\n",
    "\n",
    "Once training is complete, register your custom model with `HOOPSEmbeddings` to use it in production - see notebook HOOPS EMBEDDINGS CAD SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Next Steps**:\n",
    "- Using your registered model for similarity search\n",
    "- Indexing embeddings in vector databases\n",
    "- Querying for similar parts in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HOOPS AI (CPU-DEV)",
   "language": "python",
   "name": "hoops_ai_cpu_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
